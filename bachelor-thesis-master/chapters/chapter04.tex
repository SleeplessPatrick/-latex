\chapter{基于融合CNN与VLAD的网络模型}
如上文所述，基于深度学习的图像描述方法对动态场景具有更好的鲁棒性，但神经网络在生成全局图像描述的过程中破坏了图像的局部空间特性，对闭环检测的准确率有很大的影响，因此对神经网络的输出进行相关的处理，保留图像的空间特征非常有必要。鉴于基于传统特征的图像描述方法能够有效的保存图像的局部特性，并且基于 VLAD 方法没有损失信息，比 BoVW 对局部信息的刻画更加细致。基于这些特性，本文构建融合 VGG16 和 VLAD 的网络模型 VGG-NetVLAD，使用 VLAD 对 CNN 提取的图像特征进行编码，结合 CNN 提取抽象特征信息的能力与 VLAD 无量化损失的特性，致力于提高图像描述在闭环检测中的准确性与鲁棒性。

\begin{figure}[htbp]
	\centering
	\includegraphics[scale=0.5]{figures/chap4-flow chart.png}
	\caption{基于CNN与VLAD融合的图像描述生成流程}
\end{figure}

\section{基于CNN的图像特征提取}
VGG \ucite{Szegedy2014Going}模型是2014年于 ILSVRC 竞赛中提出的深度卷积神经网络，包含11到19层等不同深度的网络结构，相比于 AlexNet 神经网络，VGG 神经网络结构简单，其使用连续堆叠的小卷积核代替大卷积核以增加网络深度，增强了网络的表达能力，在提升了网络性能的同时减少了网络参数。VGG 中根据卷积核大小和卷积层数目的不同，可分为A，A-LRN,B,C,D,E共6种配置(ConvNet Configuration)，其中D,E两种配置较为常用，分别称为 VGG16 和 VGG19。

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.5]{figures/chap4-vgg.png}
	\caption{VGG结构配置}
	\label{vgg_con}
\end{figure}

\subsection{VGG16网络结构}
上图中，每一列对应一种结构配置。例如，图中绿色部分即指明了 VGG16 所采用的结构。我们针对 VGG16 进行具体分析发现，VGG16 共包含：

\begin{itemize}
\item13个卷积层（Convolutional Layer），分别用conv3-XXX表示

\item3个全连接层（Fully connected Layer）,分别用FC-XXXX表示

\item5个池化层（Pool layer）,分别用maxpool表示
\end{itemize}

其中，卷积层和全连接层具有权重系数，因此也被称为权重层，总数目为13+3=16，这即是
VGG16 中16的来源。(池化层不涉及权重，因此不属于权重层，不被计数)。

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.8]{figures/chap4-vgg16.png}
	\caption{VGG16 模型网络结构}
\end{figure}
 
\subsection{VGG16分块结构}
我们注意图 \ref{vgg_con}右侧，VGG16 的卷积层和池化层可以划分为不同的块（Block），从前到后依次编号为Block1~block5。每一个块内包含若干卷积层和一个池化层。例如：Block4包含：

•3个卷积层，conv3-512

•1个池化层，maxpool

并且同一块内，卷积层的通道(channel)数是相同的，例如：

•block2中包含2个卷积层，每个卷积层用conv3-128表示,即卷积核为：3x3x3，通道数都是128

•block3中包含3个卷积层，每个卷积层用conv3-256表示,即卷积核为：3x3x3，通道数都是256

\begin{figure}[htbp]
	\centering
	\includegraphics[scale=0.3]{figures/chap4-vgg16 block.png}
	\caption{按照块划分的VGG16的结构图}
\end{figure} 

\subsection{VGG16权重参数}
VGG的输入图像是 224x224x3 的图像张量(tensor),随着层数的增加，后一个块内的张量相比于前一个块内的张量：

•通道数翻倍，由64依次增加到128，再到256，直至512保持不变，不再翻倍

•高和宽变减半，由 224→112→56→28→14→7

尽管VGG的结构简单，但是所包含的权重数目却达到了139，357，544个参数。这些参数包括卷积核权重和全连接层权重。

•例如，对于第一层卷积，由于输入图的通道数是3，网络必须学习大小为3x3，通道数为3的的卷积核，这样的卷积核有64个，因此总共有(3×3×3)x64 = 1728个参数。

•计算全连接层的权重参数数目的方法为：前一层节点数×本层的节点数前一层节点数×本层的节点数。因此，全连接层的参数分别为：

o	7x7x512x4096 = 1027,645,444

o	4096x4096 = 16,781,321

o	4096x1000 = 4096000

\begin{figure}[htbp]
	\centering
	\includegraphics[scale=0.6]{figures/chap4-vgg16 weights.png}
	\caption{VGG16网络参数计算过程(不考虑偏置）}
\end{figure}

图中蓝色是计算权重参数数量的部分；红色是计算所需存储容量的部分。

\subsection{VGG16优势及缺陷}
VGG16的突出特点是简单，体现在：

1.卷积层均采用相同的卷积核参数

卷积层均表示为conv3-XXX，其中conv3说明该卷积层采用的卷积核的尺寸(kernel size)是3，即宽(width)和高(height)均为3，$3\times3$是很小的卷积核尺寸，结合其它参数(布幅stride=1，填充方式padding=same），这样就能够使得每一个卷积层(张量)与前一层(张量)保持相同的宽和高。XXX代表卷积层的通道数。

2.池化层均采用相同的池化核参数

池化层的参数均为2××2，步幅stride=2，max的池化方式，这样就能够使得每一个池化层(张量)的宽和高是前一层(张量)的1212。

3.模型是由若干卷积层和池化层堆叠(stack)的方式构成，比较容易形成较深的网络结构。

由于VGG16具有庞大的参数数目，故具有很高的拟合能力；但同时缺点也很明显：

1.即训练时间过长，调参难度大。

2.需要的存储容量大，不利于部署。


\section{基于VLAD的特征编码}
NetVLAD \ucite{Arandjelovic2017NetVLAD}是于2016年提出的一种场景识别算法，该算法改进于 VLAD，VLAD 算法以 SIFT 或该类算法为基础，对其提取的特征进行编码，得到一段较短的特征串，NetVLAD 以卷积神经网络作为基础特征提取结构，与该网络连接，实现端到端的训练。

\subsection{VLAD公式的可微化}
由上文已知VLAD 的主要流程如下：

- 对图像x的全部$N \times D$维局部特征进行 K-Means 聚类获得K个聚类中心，记为$c_k$
- 找到每个聚类中心中的所有的$X$，然后以该聚类中心为基础，计算所有的残差和：遍历所有的样本点，利用$a(x)$决定是否属于该样本点，然后计算相应的残差，最后求和，这样得到了一个聚类中心的残差和，得到$V$的一行。遍历k个聚类中心，得到$V$的k行。通过以下公式将$N \times D$维局部特征编写为一个全局特征$V$，特征向量维数为$K \times D$，其中$k\in K$,$j\in D$，公式如下：

\begin{equation}
V(j, k) = \sum_{i=1}^N a_k(x_i)( x_i(j) - c_k(j) )
\end{equation}

其中$x_i$为第i个局部图像特征，$C_k$为第k个聚类中心，$x_i(j)$和$C_k(j)$分别代表第i个特征向量和第k个聚类中心的第j个元素，$a_k(x_i)$表示第i个特征向量对应第k个聚类中心的权重，当该特征属于这个聚类中心时，权重为1，否则为0。

由于$a_k(x_i)\in\left\{0,1\right\}$，无法利用神经网络进行训练,所以 NetVLAD 层采用了一种近似的方式，将$a_k{x_i}$软分配到多个聚类中心，使其可微：

\begin{equation}
\bar{a}_k(x_i) = \frac{e^{-\alpha\left\|x_i-c_k\right\|^2}}{\sum_{k'}e^{-\alpha\left\|x_i-c_{k'}\right\|^2}}
\end{equation}

其中$\alpha$是一个正值参数，控制响应随距离大小的衰减；显然当$\alpha \to \infty$时，$\bar{a}_k(x_i)$更趋近于0和1的两级。再将 $-\alpha\left\|{x_i-c_k}\right\|^2$展开，显然$e^{-\alpha\left\|{x_i}\right\|^2}$可以被约掉，因此得到： 

\begin{equation}
\bar{a}_k(x_i) = \frac{e^{2\alpha c_k x_i-\alpha\left\|c_k\right\|^2}}{\sum_{k'}e^{2\alpha c_{k'} x_i-\alpha\left\|c_{k'}\right\|^2}} 
\end{equation}

在此令$w_k=2\alpha c_k$，$b_k=-\alpha\left\|c_k\right\|^2$,将其化为一个 softmax 函数。这样原 VLAD 公式就被改写为：   

\begin{equation}
V(j, k) = \sum_{i=1}^N \frac{e^{W_k^{T}x_i+b_k}}{\sum_{k'}e^{W_{k'}^{T}x_i+b_{k'}}}( x_i(j) - c_k(j) )
\end{equation} 

公式中$ {w_k} $、$ {b_k} $和$ {c_k} $都是 NetVLAD 需要训练的参数。原始VLAD中只有一个参数$ {c_k} $，这使得NetVLAD相对于传统的方法具有更加的灵活性，并且所有的参数在特定的任务下可以通过端到端的方式来训练得到。

\subsection{NetVLAD网络实现} 

\begin{figure}[htbp]
	\centering
	\includegraphics[scale=0.4]{figures/chap4-netvlad.png}
	\caption{NetVLAD网络结构}
\end{figure} 
 
首先，由于是 NN 的方法，故使用 CNN Feature 代替了传统 VLAD 中的 N 个局部描述子，CNN是一个全局的特征，它的 Feature Map 是$W \times H \times D$大小，那么类比于我们之前的传统方法$N \times D$， NetVLAD 目标就是将$W \times H \times D$($N=W \times H$)的特征转换为 $K \times D$的特征；其次，将整个 NetVLAD 看做一个 pooling layer，它的作用是实现降最终和 VLAD 一样获得我们想要的$K \times D$维描述子。 
 
\begin{figure}[H]
	\centering
	\includegraphics[scale=0.8]{figures/chap4-netvlad layer.png}
	\caption{NetVLAD网络实现步骤}
	\label{netvlad step}
\end{figure} 
如图 \ref{netvlad step}所示，具体实现分步骤进行：

1. soft-assignment阶段的整个过程可以公式化为一个soft-max函数$ (\sigma_k (z)=\frac{e^{z_k}}{\sum_{{k}'} e^{z_{k'}}}) $，它可以视为分为两个阶段：

- 用K个$1 \times 1$的卷积核卷积矩阵，卷积矩阵参数为$ {w_k} $，偏置项为$ {b_k} $，产生结果$ s_k(x_i)=w_K^{T}+b_k $

- 将上一步的结果送入$ \sigma_k $求得soft-assignment$ \bar{a}_k(x_i) $； 

3. 实现$(x_i (j)- c_k(j))$，也就是公式中的绿色部分，这部分就是一个减法，直接用一个 VLAD core完成；
  
4. 1~3已经实现了$V(j,k)$的计算，后面对 $V(j,k)$做两步简单的归一化（归一化可以提升检索性能），包括：

-  intra-normalization

将每一个 VLAD block（即每个聚类中心的所有残差）分别进行L2归一化，并将矩阵V转换成向量。

-  L2 normalization

对第一步得到的向量整体进行一次L2归一化，最后输出的特征向量维度为$K \times D$。

\section{VGG16-NetVLAD网络模型的框架}

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.6]{figures/chap4-vgg-netvlad.png}
	\caption{VGG16-NetVLAD网络模型}
\end{figure} 

原VGG16模型是一个多层神经网络，主要由3层类型组成：5个卷积层(conv1，conv2，conv3，conv4，conv5)，5个最大池化层(pool1，pool2，pool3，pool4，pool5)和3个完全连接的层(fc6，fc7，fc8). 最大池化层为相关特征提供平移不变性并同时减小其尺寸. 事实上，它也是通过合并底层本地信息来构建抽象表示的过程. 而对于完全连接层，前一层中的所有神经元都完全连接到当前层的每个单个神经元. 全连接层主要应用在神经网络的高层网络中，这是因为其有利于图像分类和图像检索应用.

输入层是一幅224×224×3的三通道图像，卷积层和全连接层的激活函数均采用修正线性单元(Rectified Linear Unit, ReLU). ReLU是目前使用最多的激活函数，主要因为其收敛更快，并且能保持同样效果. 标准的ReLU函数为

\begin{equation}
f(x) = max(x,0)
\end{equation}

当$x>0$时，输出$x$ ；当$x \leq 0$时，输出为0。 

ReLU 模块如图 \ref{relu_mod}所示

\begin{figure}[htbp]
	\centering
	\includegraphics[scale=0.4]{figures/chap4-RELU.png}
	\caption{ReLU 模块示意图}
	\label{relu_mod}
\end{figure}

原 VGG 网络输出的结果为图像的分类，不适合用于图像特征的表达。相比于层次更深维度更低的全连接层，全连接层之前的池化层更加适用于视觉闭环检测。池化层同时保留输入图像的大部分空间信息和丰富的语义表示，而全连接层失去了绝大部分空间信息只保留了图像高阶语义信息。

因此对VGG16网络进行了裁剪，去掉了最后一个卷积层conv5-3之后的池化层和全连接层，包括RELU激活函数，并将NetVLAD层连接到卷积层conv5-3之后，作为新的池化层，并将其输出作为图像的全局特征描述符。NetVLAD层将VLAD的思想引入到了卷积神经网络中，构建新的网络模型VGG-NetVLAD。


\section{VGG16-NetVLAD网络模型的训练}
为了训练本文提出的NetVLAD网络，需要解决两个主要的问题：

1.怎么聚合足够多的标注训练数据来训练网络？
 
2.如何得到一个合适的损失函数？

为了解决这两个方法，首先将使用具有极大数量的谷歌时光机（Google Street View Time Machine）弱标签全景图像集作为VGG16-NetVLAD网络的训练集。另外，设计了一个新的弱监督排序损失函数用于处理数据集中不完整和具有噪声的位置信息标注。

\subsection{弱监督性数据集}
采用Google Street View Time Machine弱标签全景图像集训练构建的网络模型，获得最优参数$ {w_k} $、$ {b_k} $和$ {c_k} $。数据集中图片为全景图，每个全景图由一组不同方向的透视图组成，每个透视图只有代表其在地图上大致位置的 GPS 标签，属于弱监督信息。

\begin{figure}[H]
	\centering
	\includegraphics[scale=0.4]{figures/chap4-Google Street View Time Machine.png}
	\caption{谷歌街景时光机例图}
\end{figure}
 
每一列显示在不同时间从附近位置的全景图生成的透视图图像。利用这些图像资源来训练网络，使其学会不受视点和照明(a-c)和适当的遮挡(b)等变化的影响。该图像数据集还可训练网络抑制令人困惑的视觉信息，例如云(a)，车辆和人(b-c)，并选择忽略植被或学习季节不变的植被表示(a - c)。
该新颖的数据源对于学习用于位置识别的图像表示是宝贵的。像上图所示，相同的位置在不同的时间和季节被描绘，为学习算法提供了关键信息，该算法可以用来发现哪些特征是有用的或令人分心的，以及图像表示应该对哪些变化保持不变，以便获得良好的位置识别性能。

该图像数据集的缺点是它只能提供不完整和嘈杂的监督。每个Time Machine全景图都带有一个GPS标签，只给出它在地图上的大致位置，可以用来识别附近的全景图，但不提供所描绘的场景部分之间的对应关系。具体来说，由于测试查询是来自照相手机的透视图像，所以每个全景图由在不同方向和两个仰角上均匀采样的一组透视图像表示。每个透视图像都标有源全景图的GPS位置。因此，两个地理上接近的透视图像不一定描绘相同的对象，因为它们可能面对不同的方向或可能发生遮挡(例如，两个图像彼此相距一角)。

\subsection{NetVLAD通过监督学习获得聚类中心的好处}

\begin{figure}[htbp]
	\centering
	\includegraphics[scale=0.8]{figures/chap4-Training Cluster Center.png}
	\caption{监督训练VLAD的优势}
	\label{tra_adv}
\end{figure} 
将$c_k$作为学习参数的优点通过图 \ref{tra_adv}可得到直观显示：
  
传统 VLAD 的中心是聚类出来的，没有监督的标签数据 ckVLAD ，在聚类时我们使用了很多图像，这些图像的描述符之间没有关系，那么也就很可能把本来不是一个物体的描述符聚为一类，使得原本期望的类内描述符都是一个物体的特征不太容易达到。而在使用监督数据进行训练时，已知图像数据属于同一物体，那么训练时就可以只把属于同一物体的特征聚在一起而把不是的划分到其他类别，这样就可能学习出一个更好的ckNetVLAD聚类中心，使得最终的特征更有区分度。

\subsection{弱监督排序损失函数}
通过弱监督三元组排序损失算法(triplet ranking loss)来处理谷歌街景时光机图像位置标注的不完整和噪声。将整个网络看做一个特征提取函数$F_\theta$ ，训练目标为：给定一个查询图像q，要在数据集所有图像$I_i$中找到与q位置距离最近的图像$I_i*$。数据集根据GPS信息将与其距离相近(10米以内)的图像作为正样本集合$\left\{p_i^q\right\}$,距离很远(超过25米)的图像作为负样本集合$\left\{n_j^q\right\}$, 构建一个新的三元组数据集(q,$\left\{p_i^q\right\}$,$\left\{n_j^q\right\}$), 在三元组中，正样本$\left\{p_i^q\right\}$中至少包含一幅能与查询图像匹配的图像。训练每一个三元组时，要学习一种最优的图像表示方法$f_\theta$使得查询图像q与最佳匹配图像$\left\{p_{i*}^q\right\}$的距离小于查询图像q与任何一个负样本图像的距离：

\begin{equation}
\mathrm { d } \theta（q,p_{i*}^q）< \mathrm { d } \theta（q,n_j^q）,\forall j
\end{equation}

并且正样本中距离最近的应该就是我们想要的最近图片：

\begin{equation}
p_i*^q = \mathop{\arg\min}_{p_i^q}\mathrm { d } \theta（q,p_i^q）
\end{equation}

据此构造如下损失函数( loss)：

\begin{equation}
L_\theta = \sum_{j} l(\mathop {\min}\mathrm { d } ^2 \theta(q,p_i^q)+m-\mathrm { d } ^2 \theta(q,p_i^q))
\end{equation}

其中l为hinge loss函数：l(x)＝max(x,0)，m为附加常数,是一个常量表示给负样本设置的差额(margin)。$L_\theta$代表所有负样本图像的损失之和，对于每一个负样本图像，当其与查询图像的距离大于查询与最佳匹配图像的距离与m之和，则损失为0，否则其损失值与m成正比。通过采用随机梯度下降法对参数进行优化，使网络可提取最优的图像表达。

\section{本章小结}
结合上一章的分析，提出了融合 CNN 与 VLAD 特征的图像描述方法，搭建 VGG16-NetVLAD 卷积神经网络模型的框架，并对构成网络模型的VGG16网络以及NetVLAD层进行了详细介绍，然后介绍了模型的训练方法及得出损失函数的计算过程。

\clearpage
\endinput
